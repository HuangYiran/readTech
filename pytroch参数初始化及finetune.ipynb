{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文内容主要来自：\n",
    "- http://blog.csdn.net/victoriaw/article/details/72872036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch提供了多种参数初始化函数：\n",
    "- torch.nn.init.constant(tensor, val)\n",
    "- torch.nn.init.normal(tensor, mean=0, std=1)\n",
    "- torch.nn.init.xavier_uniform(tensor, gain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  1.4966  0.9459 -4.0601  ...  -2.6735  1.8151 -3.2782\n",
      "  2.7360  2.3130 -1.3590  ...   0.9779 -0.3665  4.2067\n",
      "  3.0140 -3.3658 -3.2186  ...   3.4620 -1.2174  0.8918\n",
      "           ...             ⋱             ...          \n",
      " -1.0376  0.8901  2.2509  ...  -3.2813 -2.1093 -0.7652\n",
      " -0.7438  0.9604  4.2652  ...   0.2865 -1.7738 -1.3023\n",
      " -4.0031 -2.0784 -0.4711  ...   2.6196 -1.7623 -3.6635\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.0641 -2.6989  1.1737  ...  -1.0922  1.6751  1.5942\n",
      " -3.0541  1.0181  3.3403  ...   3.5644  0.0527 -2.9716\n",
      "  3.1716  3.2811 -0.9251  ...   1.7270  3.6800  2.9606\n",
      "           ...             ⋱             ...          \n",
      "  1.1953  3.4653 -3.7302  ...  -0.6696  2.6366  2.1886\n",
      "  0.0554 -0.0215 -1.9935  ...   0.5594 -0.3820  1.8665\n",
      " -2.8589  0.8501 -0.8863  ...  -4.0536  3.0960 -1.8935\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.5180 -2.5176  0.9794  ...  -2.9021 -2.7209 -1.3858\n",
      "  0.2433 -1.2021  2.3269  ...   2.1010 -1.7316  0.0584\n",
      " -1.2842  1.5945  0.7379  ...   2.6818  3.9700  1.6218\n",
      "           ...             ⋱             ...          \n",
      " -0.2887 -3.5771  2.8126  ...   2.1686 -1.9425 -3.6672\n",
      "  1.1548 -0.6723 -1.9347  ...  -1.8144  1.4697 -2.7758\n",
      " -0.0806 -1.5957  0.5354  ...  -0.5251  3.8129  2.7862\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.2205 -1.0189 -3.7470  ...  -0.1217 -2.2574 -4.0503\n",
      "  2.6544  1.7818  0.4264  ...  -3.0186  1.0783  0.6074\n",
      " -1.3578  1.2438 -1.4447  ...   0.7183  2.5800  0.2936\n",
      "           ...             ⋱             ...          \n",
      " -1.9504  3.1515  1.4442  ...  -3.5503 -0.7201 -4.0495\n",
      " -2.4453 -3.9054  3.4720  ...   2.7591 -3.1508 -0.3147\n",
      " -1.6836 -1.1575  0.1743  ...  -3.0667 -2.8342  1.1479\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.4724  0.6555 -0.7009  ...  -4.0167 -1.0152  0.8324\n",
      "  3.4454 -3.6556 -2.3440  ...  -0.3282  3.6602 -2.8100\n",
      "  2.6085 -0.8089 -3.6787  ...  -2.7595 -4.0694 -2.6420\n",
      "           ...             ⋱             ...          \n",
      " -3.2752  0.2105 -1.5570  ...  -3.2290  3.7172 -0.5796\n",
      " -3.0201 -0.5210  2.8286  ...  -0.1933 -0.3642 -2.6511\n",
      " -0.1946  0.7494 -3.0622  ...  -3.2156 -1.9754  1.8374\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  3.1790 -2.9498  1.9335  ...   2.4324 -3.1481 -1.4088\n",
      " -3.7220  2.1703  3.5426  ...   1.8142  3.8680  1.0378\n",
      "  3.1017 -1.3059  0.9722  ...  -1.9794 -2.6130  3.5202\n",
      "           ...             ⋱             ...          \n",
      "  3.4929  1.9056  1.9772  ...   3.2291  3.7494  0.9614\n",
      " -1.5906 -0.7105 -2.1905  ...  -3.0272 -1.9984 -1.1302\n",
      " -1.2465 -0.6047  1.8912  ...  -3.0508 -1.8541 -1.2648\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -2.6627 -2.7669  2.6680  ...  -1.1615 -2.8224 -1.7260\n",
      "  2.1208  1.7370  3.4665  ...  -2.1734 -2.3115 -1.0301\n",
      "  0.9830  2.9182 -1.6472  ...  -2.0471  1.0737  2.8106\n",
      "           ...             ⋱             ...          \n",
      "  2.9990 -1.0337  4.2108  ...   1.9874  3.9530 -0.6800\n",
      " -1.0689 -3.3920 -1.5248  ...  -3.8253 -0.2676  3.7916\n",
      " -0.3263 -4.1977  1.7081  ...  -1.5162  0.8969 -0.1893\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.8446 -3.7513  0.4843  ...   4.2279  3.2060  2.7109\n",
      " -2.6083  0.0948  4.1567  ...  -4.1287 -0.7109  2.7757\n",
      "  3.3962  1.5602  3.9412  ...  -2.9507  1.3860  3.6495\n",
      "           ...             ⋱             ...          \n",
      " -3.7517  0.0708 -1.3867  ...  -1.7002 -3.2447  3.0470\n",
      " -1.9569 -3.7125  3.0658  ...   1.4838  0.7711 -2.8369\n",
      " -1.4125  3.6640 -0.1931  ...  -2.5673  3.0104 -3.6879\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -0.0152 -2.1387  1.2701  ...  -0.0995  1.0267 -2.5564\n",
      "  2.7590 -4.1159 -1.3503  ...  -3.7718 -4.1796  0.2544\n",
      " -1.1886  2.9259 -0.5410  ...  -4.0702 -2.3067 -0.1608\n",
      "           ...             ⋱             ...          \n",
      " -2.4689  1.9140  4.1600  ...  -3.0913  4.0866  3.7271\n",
      " -2.8684  3.5383 -2.1887  ...   1.3261 -2.8998  1.8037\n",
      " -2.6930 -0.5966 -3.4001  ...  -3.3596 -0.7754  1.0416\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(61,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  0.1258  4.0404  1.2403  ...   2.0520  3.4116  3.3610\n",
      " -0.1824 -1.7711 -1.7906  ...  -4.1624 -1.8822 -2.7487\n",
      "  1.5659 -1.4735  1.1055  ...  -0.0819 -2.5724  0.8123\n",
      "           ...             ⋱             ...          \n",
      "  2.3136  0.7489 -1.9834  ...   4.0407 -1.8459 -2.5800\n",
      "  1.8322  1.6546 -1.7458  ...   3.0262  2.2516 -2.8135\n",
      "  0.9848  2.4187  3.2823  ...  -0.4324 -1.9682 -3.8686\n",
      "\n",
      "(61,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  0.0510 -3.3287 -3.1498  ...   1.3363  1.8818  1.5953\n",
      "  2.2145 -2.5145  2.4714  ...  -2.5380 -3.7338 -4.0620\n",
      " -1.6341  2.0217 -2.1600  ...   1.1940 -0.9985  4.2745\n",
      "           ...             ⋱             ...          \n",
      "  0.7526 -3.8933 -3.0915  ...   3.9765  2.6754 -1.7055\n",
      " -3.7677  1.7190  1.9957  ...  -3.9808 -3.9003  1.1356\n",
      " -2.4303  2.8103  1.4787  ...   2.6022  2.0836  4.1874\n",
      "\n",
      "(61,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -1.9562 -2.2705 -1.8938  ...  -1.7639  0.6311 -3.5402\n",
      "  3.7730 -2.0102 -3.2969  ...  -0.8275  4.0846  1.2351\n",
      "  1.3346 -1.1916 -2.5900  ...  -0.6336  0.5274 -1.2180\n",
      "           ...             ⋱             ...          \n",
      "  2.9967 -1.6700 -1.2587  ...  -1.5843  3.4337  2.8483\n",
      "  3.4801 -3.2132 -3.5627  ...  -1.9948  1.9702 -1.8304\n",
      " -0.9143 -0.1519 -3.0746  ...   1.9953  2.9999  3.5775\n",
      "     ⋮ \n",
      "\n",
      "(62,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -3.1884 -3.5220  0.7536  ...   3.3396  3.4324 -0.3033\n",
      "  2.1775 -0.0234  0.7316  ...   0.5884 -1.9495 -0.2486\n",
      " -2.1583  1.0629  3.9807  ...  -2.0080  2.5641  1.9439\n",
      "           ...             ⋱             ...          \n",
      "  1.2688 -3.0020  0.4500  ...  -0.9683 -3.1946  4.0299\n",
      " -1.4266  3.4703  1.4220  ...   0.4214 -1.2366 -1.4709\n",
      "  0.5629 -0.4298 -2.0820  ...   3.8303 -0.3498  1.4179\n",
      "\n",
      "(62,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  3.9288 -0.2962  3.9780  ...  -4.2075 -0.4173  1.1800\n",
      "  2.2860 -3.0323  2.8153  ...  -3.7509 -0.3265 -2.0018\n",
      " -0.4973  1.1429 -4.1464  ...  -0.8409 -0.4768  0.5967\n",
      "           ...             ⋱             ...          \n",
      "  1.8712 -3.1080 -3.7432  ...  -0.1907 -0.7339 -2.4606\n",
      " -0.2633  1.9176  2.2137  ...  -2.1150  0.1859  0.4823\n",
      " -3.3347 -0.4251  0.8544  ...   3.7364 -0.1373  4.0139\n",
      "\n",
      "(62,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  4.0950  0.4836  3.7909  ...  -0.0255 -0.4673 -0.9995\n",
      " -2.6949 -4.1608 -0.5962  ...  -0.0971 -2.2272  3.3127\n",
      " -0.6789 -2.3995  1.1611  ...  -3.2750 -4.2494  1.3608\n",
      "           ...             ⋱             ...          \n",
      " -2.1424  3.5645 -0.8575  ...  -2.9586  3.3417  4.0123\n",
      " -0.1022  0.3711  1.0097  ...  -3.5462 -1.9789  1.8576\n",
      "  2.2301  1.5335 -3.1026  ...  -0.0188  0.4433  2.5302\n",
      "     ⋮ \n",
      "\n",
      "(63,0 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  2.2301  0.6927 -3.1250  ...  -2.6783 -0.8703  1.7131\n",
      "  0.5310 -3.5303 -0.6470  ...  -0.5647 -2.7666  3.0366\n",
      " -4.0891  0.8380  2.8331  ...  -2.1681  4.2621 -2.4833\n",
      "           ...             ⋱             ...          \n",
      "  2.3451 -1.0230 -0.0144  ...  -0.6063  1.2538 -1.2662\n",
      "  2.0754  0.9337 -3.1040  ...  -0.8867 -0.8473  0.8677\n",
      "  0.4919 -3.7490  3.2795  ...  -0.8333 -3.2305  0.5432\n",
      "\n",
      "(63,1 ,.,.) = \n",
      "1.00000e-02 *\n",
      " -3.1652  2.9502  3.5356  ...   2.8974  3.7296 -4.2701\n",
      "  0.3412 -1.8815 -4.1906  ...   3.1431 -3.2646 -4.0637\n",
      "  0.2497 -2.4955  2.4250  ...  -0.8891 -0.5455 -3.4434\n",
      "           ...             ⋱             ...          \n",
      "  1.7287 -1.8438  2.5474  ...  -1.3186 -1.8965 -2.5283\n",
      " -1.7944 -0.6908 -4.1575  ...   3.4677 -3.9112  1.7965\n",
      "  2.7610 -0.0357  3.8957  ...  -4.0405  0.4503 -3.4663\n",
      "\n",
      "(63,2 ,.,.) = \n",
      "1.00000e-02 *\n",
      "  1.2024 -4.2146  1.6827  ...  -2.4056  1.5576  2.9148\n",
      "  3.2311 -2.5281 -2.6353  ...   1.5413 -3.1336 -1.8420\n",
      "  0.5764 -2.0157  3.7482  ...  -1.3934 -0.7102 -4.2144\n",
      "           ...             ⋱             ...          \n",
      " -0.1144 -4.0577  4.1737  ...  -0.3003  0.3060 -2.2068\n",
      "  1.6084  3.2922 -1.9107  ...  -0.3066  1.4184 -0.9298\n",
      " -2.3245  2.0989 -0.6381  ...  -2.6380  1.7541  1.5976\n",
      "[torch.FloatTensor of size 64x3x7x7]\n",
      ", Parameter containing:\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      " 0.1000\n",
      "[torch.FloatTensor of size 64]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "init.xavier_uniform(conv1.weight)\n",
    "init.constant(conv1.bias, 0.1)\n",
    "print(conv1.weight, conv1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的语句是对网络的某一层参数进行初始化。如何对整个网络的参数进行初始化定制呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname=m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        xavier(m.weight.data)\n",
    "        xavier(m.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不建议访问以下划线为前缀的成员，他们是内部的，如果有改变不会通知用户。更推荐的一种方法是检查某个module是否是某种类型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "# 使用isinstance来判断m属于什么类型\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "# m中的weight，bias其实都是Variable，为了能学习参数以及后向传播\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "net = Net()\n",
    "net.apply(weights_init) #apply函数会递归地搜索网络内的所有module并把参数表示的函数应用到所有的module上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune\n",
    "往往在加载了预训练模型的参数之后，我们需要finetune模型，可以使用不同的方式finetune。\n",
    "##### 局部微调\n",
    "有时候我们加载了训练模型后，只想调节最后的几层，其他层不训练。其实不训练也就意味着不进行梯度计算，PyTorch中提供的requires_grad使得对训练的控制变得非常简单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.optim as optim\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# 替换最后的全连接层， 改为训练100类\n",
    "# 新构造的模块的参数默认requires_grad为True\n",
    "model.fc = nn.Linear(512, 100)\n",
    "\n",
    "# 只优化最后的分类层\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 全局微调\n",
    "有时候我们需要对全局都进行finetune，只不过我们希望改换过的层和其他层的学习速率不一样，这时候我们可以把其他层和新层在optimizer中单独赋予不同的学习速率。比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, 100)\n",
    "ignored_params = list(map(id, model.fc.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model.parameters())\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "            {'params': base_params},\n",
    "            {'params': model.fc.parameters(), 'lr': 1e-2}\n",
    "            ], lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中base_params使用1e-3来训练，model.fc.parameters使用1e-2来训练，momentum是二者共有的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py27",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
